---
title: "preprocess"
author: "Hachem Brahimi"
date: "2025-04-25"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(lubridate)
```
```{r}
data <- read_csv("hourly_data.csv")
data
```
```{r}

normalize <- function(x) (x - min(x, na.rm = TRUE)) / 
                      (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))
groups <- data %>%
  mutate(times=make_datetime(YEAR, MO, DY, HR)) %>% 
  group_by(LON, LAT) %>% 
  select(LON, LAT, times, RH2M, T2M, PRECTOTCORR) %>% 
  #mutate(across(c(RH2M, T2M, PRECTOTCORR), normalize)) %>%
  group_split()


```

```{r}
# Parameters
overlap <- 3  # Number of steps to overlap between windows
max_length <- 3  # Length of each input window
target_length <- 1  # Number of steps to predict

# Initialize an empty list to store the results from each group
all_groups_data <- list()


total_iterations <- 0  

# First pass to calculate total iterations
for (g in groups) {
  valid_rows <- nrow(g) - max_length - target_length + 1
  if (valid_rows > 0) {
    start_index <- seq(1, valid_rows, by = max_length - overlap + 1)
    total_iterations <- total_iterations + length(start_index)
  }
}


counter <- 0


for (g_idx in seq_along(groups)) {
  g <- groups[[g_idx]]
  
  # Calculate valid start indices FOR THIS GROUP
  valid_rows <- nrow(g) - max_length - target_length + 1
  if (valid_rows < 1) next  # Skip groups with insufficient data
  
  start_index <- seq(1, valid_rows, by = max_length - overlap + 1)
  
  
  n_windows <- length(start_index)
  data_matrix <- matrix(
    nrow = n_windows,
    ncol = (max_length * 3) + (target_length * 3) + 2 + 1  # 3 vars * time steps + targets + coords
  )
  
  
  for (i in seq_along(start_index)) {
    start <- start_index[i]
    end_input <- start + max_length - 1
    end_target <- end_input + target_length
    
    
    temporal_part <- g[start:end_input, c("RH2M", "T2M", "PRECTOTCORR")]
    flattened_part <- as.vector(t(temporal_part))  
    
    
    target_part <- g[(end_input + 1):end_target, c("RH2M", "T2M", "PRECTOTCORR")]
    flattened_target <- as.vector(t(target_part))
    
    
    spatial_info <- as.numeric(g[start, c("LON", "LAT")])
    
    timestamp <- as.numeric(g[end_input + 1, "times"])  
    
    data_matrix[i, ] <- c(
      flattened_part,
      flattened_target,
      spatial_info,
      timestamp
    )
    
    # Update progress
    counter <- counter + 1
    cat(sprintf("Processing group %d/%d: %.2f%%\r",
                g_idx, length(groups),
        counter/total_iterations*100)
    )
  }
  
  # Store group results
  all_groups_data[[g_idx]] <- data_matrix
}

# Combine all groups 
final_data_matrix <- do.call(rbind, all_groups_data)
final_data_matrix <- as_tibble(final_data_matrix)

colnames(final_data_matrix) <- c("RH2M-t3", "T2M-t3", "PRECTOTCORR-t3", 
                                 "RH2M-t2", "T2M-t2","PRECTOTCORR-t2",
                                 "RH2M-t1", "T2M-t1","PRECTOTCORR-t1",
                                 "RH2M-t", "T2M-t","PRECTOTCORR-t",
                                 "LON", "LAT", "time")

```
```{r}
final_data_matrix
```


```{r}
# Save the final data matrix to a CSV file
write_csv(final_data_matrix, "Prepared_data.csv")
```

